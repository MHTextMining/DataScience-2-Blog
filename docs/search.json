[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataScience 2 Blog",
    "section": "",
    "text": "Analysebericht\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 10, 2023\n\n\nMarkus H√§fner\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html",
    "href": "posts/Hate Speech Prediction/index.html",
    "title": "Analysebericht",
    "section": "",
    "text": "In this blog post we will be solving classification problems by trying to identify hate speech in tweets using machine learning algorithms. The data that we will be using is sourced from (Wiegand 2019)."
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#train---data",
    "href": "posts/Hate Speech Prediction/index.html#train---data",
    "title": "Analysebericht",
    "section": "Train - Data",
    "text": "Train - Data\n\nLoad Data\nWe start by reading in the training data right from text file provided by (Wiegand 2019).\n\nd_train <- \n  data_read(\"data/germeval2018.training.txt\",\n         header = FALSE)\n\nkable(head(d_train))\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\n\n\n\n\n(corinnamilborn?) Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\nOTHER\nOTHER\n\n\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\nOTHER\nOTHER\n\n\n(ahrens_theo?) fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\nOTHER\nOTHER\n\n\n(dushanwegner?) Amis h√§tten alles und jeden gew√§hlt‚Ä¶nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n\n\n(spdde?) kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\nOFFENSE\nINSULT\n\n\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\nOTHER\nOTHER\n\n\n\n\n\n\n\nRenaming Columns\n\nnames(d_train) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nAdding ID Column\n\nd_train_id <- d_train %>% \n  mutate(id = row_number())"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#test---data",
    "href": "posts/Hate Speech Prediction/index.html#test---data",
    "title": "Analysebericht",
    "section": "Test - Data",
    "text": "Test - Data\n\nLoad Data\nSame procedure as with our training data.\n\nd_test <- \n  data_read(\"data/germeval2018.test.txt\",\n         header = FALSE)\n\nkable(head(d_test))\n\n\n\n\n\n\n\n\n\nV1\nV2\nV3\n\n\n\n\nMeine Mutter hat mir erz√§hlt, dass mein Vater einen Wahlkreiskandidaten nicht gew√§hlt hat, weil der gegen die Homo-Ehe ist ‚ò∫\nOTHER\nOTHER\n\n\n(Tom174_?) (davidbest95?) Meine Reaktion; |LBR| Nicht jeder Moslem ist ein Terrorist. Aber jeder Moslem glaubt an √úberlieferungen, die Gewalt und Terror beg√ºnstigen.\nOTHER\nOTHER\n\n\n#Merkel rollt dem Emir von #Katar, der islamistischen Terror unterst√ºtzt, den roten Teppich aus.Wir brauchen einen sofortigen #Waffenstopp!\nOTHER\nOTHER\n\n\n‚ÄûMerle ist kein junges unschuldiges M√§dchen‚Äú Kch‚Ä¶‚Ä¶. üò± #tatort\nOTHER\nOTHER\n\n\n(umweltundaktiv?) Asylantenflut bringt eben nur negatives f√ºr Deutschland. Drum Asylanenstop und R√ºckf√ºhrung der Mehrzahl.\nOFFENSE\nABUSE\n\n\n(_StultaMundi?) Die Bibel enth√§lt ebenfalls Gesetze des Zivil- und Strafrechts.\nOTHER\nOTHER\n\n\n\n\n\n\n\nRenaming Columns\n\nnames(d_test) <- c(\"text\", \"c1\", \"c2\")\n\n\n\nAdding ID Column\n\nd_test_id <- d_test %>% \n  mutate(id = row_number())"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#classifiers",
    "href": "posts/Hate Speech Prediction/index.html#classifiers",
    "title": "Analysebericht",
    "section": "Classifiers",
    "text": "Classifiers\nLets take a closer look at how our data is labeled. How many tweets are considered Hate-Speech?\n\nkable(d_train %>% \n  filter(c1 == \"OFFENSE\") %>%\n  nrow() / nrow(d_train))\n\n\n\n\nx\n\n\n\n\n0.3369934\n\n\n\n\n\n-> Seems like we have 1/3 tweets, that contain hate-speech. and 2/3 normal ones. We wont really be taking classifier 2 (c2) into account during our analysis, but lets see what type of Hate-Speech ist the most common one.\n\nkable(d_train_id %>% \n  count(c2))\n\n\n\n\nc2\nn\n\n\n\n\nABUSE\n1022\n\n\nINSULT\n595\n\n\nOTHER\n3321\n\n\nPROFANITY\n71\n\n\n\n\n\n-> Every tweet that has been classified as ‚ÄúOffense‚Äù is categorized in either of the three categories PROFANITY, ABUSE, INSULT or OTHER. It seems like most hate speech cases are due to abuse."
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#text",
    "href": "posts/Hate Speech Prediction/index.html#text",
    "title": "Analysebericht",
    "section": "Text",
    "text": "Text\n\nWord Frequency\nLets see what the 20 most used words are.\n\nfrequent_terms <- qdap:::freq_terms(d_train$text, 100)\n\nggplot(frequent_terms[1:20,], aes(x=FREQ, y=WORD, fill=WORD))+\n  geom_bar(stat=\"identity\")+\n  theme_minimal()+\n  theme(axis.text.y = element_text(angle = 0, hjust = 1))+\n  ylab(\"\")+\n  xlab(\"Most frequently used words\")+\n  guides(fill=FALSE)\n\n\n\n\nIts not odd that the most used words are just fillwords. What we can conclude from that is that it will be really important for our later prediction to use stopwords. Lets try again using stopwords.\n\nfrequent_terms_sw <- qdap:::freq_terms(d_train$text, stopwords = stopwords_de, 100)\n\nggplot(frequent_terms_sw[1:20,], aes(x=FREQ, y=WORD, fill=WORD))+\n  geom_bar(stat=\"identity\")+\n  theme_minimal()+\n  theme(axis.text.y = element_text(angle = 0, hjust = 1))+\n  ylab(\"\")+\n  xlab(\"Most frequently used words excluding stopwords\")+\n  guides(fill=FALSE)\n\n\n\n\nLets plot a wordcloud, just because we can.\n\nwordcloud(words = frequent_terms_sw$WORD, \n          freq = frequent_terms_sw$FREQ, \n          max.words = 100, \n          colors = bluebrown_colors())\n\n\n\n\nCool to look at. On first sight we can already see that a lot of words refer tagged users such as feldenfrizz."
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#adding-text_length-as-variable",
    "href": "posts/Hate Speech Prediction/index.html#adding-text_length-as-variable",
    "title": "Analysebericht",
    "section": "Adding Text_length as Variable",
    "text": "Adding Text_length as Variable\nNice to have!\n\nd_train_tl <-\n  d_train_id %>% \n  mutate(text_length = str_length(text))\n\nkable(head(d_train_tl))\n\n\n\n\n\n\n\n\n\n\n\ntext\nc1\nc2\nid\ntext_length\n\n\n\n\n(corinnamilborn?) Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\nOTHER\nOTHER\n1\n109\n\n\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\nOTHER\nOTHER\n2\n142\n\n\n(ahrens_theo?) fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\nOTHER\nOTHER\n3\n69\n\n\n(dushanwegner?) Amis h√§tten alles und jeden gew√§hlt‚Ä¶nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n4\n140\n\n\n(spdde?) kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\nOFFENSE\nINSULT\n5\n136\n\n\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\nOTHER\nOTHER\n6\n284"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#sentiment-analysis",
    "href": "posts/Hate Speech Prediction/index.html#sentiment-analysis",
    "title": "Analysebericht",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nFor our sentiments we will be using SentiWS by (Remus, Quasthoff, and Heyer 2010). The list contains a total of 16,406 positive and 16,328 negative german word forms.\n\nsentiments <- read_csv(\"data/sentiments.csv\")\n\nTo apply the sentiments we first need to ‚Äútokenize‚Äù our text. That way we will be able to apply a sentiment to each word.\n\nd_train_unnest <-\n  d_train_tl %>% \n  unnest_tokens(input = text, output = token)\n\nkable(head(d_train_unnest))\n\n\n\n\nc1\nc2\nid\ntext_length\ntoken\n\n\n\n\nOTHER\nOTHER\n1\n109\ncorinnamilborn\n\n\nOTHER\nOTHER\n1\n109\nliebe\n\n\nOTHER\nOTHER\n1\n109\ncorinna\n\n\nOTHER\nOTHER\n1\n109\nwir\n\n\nOTHER\nOTHER\n1\n109\nw√ºrden\n\n\nOTHER\nOTHER\n1\n109\ndich\n\n\n\n\n\nNow can combine our two datasets and match each word its own sentiment value.\n\nd_train_senti <- \n  d_train_unnest %>%  \n  inner_join(sentiments %>% select(-inflections), by = c(\"token\" = \"word\"))\n\nkable(head(d_train_senti))\n\n\n\n\nc1\nc2\nid\ntext_length\ntoken\nneg_pos\nvalue\n\n\n\n\nOTHER\nOTHER\n1\n109\ngewinnen\npos\n0.0040\n\n\nOTHER\nOTHER\n2\n142\nkritisieren\nneg\n-0.3466\n\n\nOTHER\nOTHER\n6\n284\nwidersprechen\nneg\n-0.3540\n\n\nOTHER\nOTHER\n6\n284\nrein\npos\n0.0040\n\n\nOTHER\nOTHER\n6\n284\nleicht\npos\n0.0040\n\n\nOTHER\nOTHER\n6\n284\nr√ºckl√§ufig\nneg\n-0.0544\n\n\n\n\n\nLets take a look at our tweets again.\n\ntrain_sentiments <-\n  d_train_senti %>% \n  group_by(id, neg_pos) %>% \n  summarise(mean = mean(value))\n\nAnd spread the positive/negative values into their own respective columns.\n\ntrain_sentiments_spread <-\n  train_sentiments %>% \n  pivot_wider(names_from = \"neg_pos\", values_from = \"mean\")\n\nkable(head(train_sentiments_spread))\n\n\n\n\nid\npos\nneg\n\n\n\n\n1\n0.0040\nNA\n\n\n2\nNA\n-0.3466\n\n\n6\n0.0040\n-0.2042\n\n\n8\nNA\n-0.5023\n\n\n9\n0.5161\nNA\n\n\n11\n0.0040\nNA\n\n\n\n\n\nFinally lets unite our ‚Äúsentimented‚Äù data with our original data again.\n\nd_train_senti <-\n  d_train_tl %>% \n  full_join(train_sentiments_spread)\n\nJoining, by = \"id\"\n\nkable(head(d_train_senti))\n\n\n\n\n\n\n\n\n\n\n\n\n\ntext\nc1\nc2\nid\ntext_length\npos\nneg\n\n\n\n\n(corinnamilborn?) Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\nOTHER\nOTHER\n1\n109\n0.004\nNA\n\n\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\nOTHER\nOTHER\n2\n142\nNA\n-0.3466\n\n\n(ahrens_theo?) fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\nOTHER\nOTHER\n3\n69\nNA\nNA\n\n\n(dushanwegner?) Amis h√§tten alles und jeden gew√§hlt‚Ä¶nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n4\n140\nNA\nNA\n\n\n(spdde?) kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\nOFFENSE\nINSULT\n5\n136\nNA\nNA\n\n\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\nOTHER\nOTHER\n6\n284\n0.004\n-0.2042"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#profanities",
    "href": "posts/Hate Speech Prediction/index.html#profanities",
    "title": "Analysebericht",
    "section": "Profanities",
    "text": "Profanities\nTo Create a list of profanites we are going to combine data from three different sources.\n(1) A publicly available list of over 6000 german profane words (‚ÄúSchimpfwortliste,‚Äù n.d.).\n(2) schimpfwoerter from the package (Sauer 2023) provides another list of german profanities.\n(3) (Ahn, n.d.) curated a list of 1,300+ English terms that could be found offensive. Obviously our tweets are in german. But it seems like nowadays a lot of people are using english words or even a mixes of english and german words, so we will give it a try and then decide.\n\nLoad/Rename Lists\n\nprofanities1 <- \n  data_read(\"data/profanities.txt\",\n         header = FALSE)\n\n\n profanities2 <- \n   schimpfwoerter %>% \n   mutate_all(str_to_lower) %>% \n   rename(V1 = \"word\")\n\n\nprofanities3 <- \n  data_read(\"data/profanities_en.txt\",\n         header = FALSE)\n\n\n\nMerge Lists\nWe are applying the function distinct() to remove duplicates.\n\nprofanities <-\n  profanities1 %>% \n  bind_rows(profanities2) %>%\n  bind_rows(profanities3) %>%\n  distinct()\n\nkable(nrow(profanities))\n\n\n\n\nx\n\n\n\n\n7572\n\n\n\n\n\nTokenizing and applying our curated profanity list.\n\nd_train_prof <- \nd_train_unnest %>% \n  select(id, token) %>% \n  mutate(profanity = token %in% profanities$V1)\n\nHow many words are considered as profanities?\n\nkable(d_train_prof %>% \n  count(profanity))\n\n\n\n\nprofanity\nn\n\n\n\n\nFALSE\n96170\n\n\nTRUE\n4047\n\n\n\n\n\nIt seems like about one third of our total words are considered as profane. This seems a bit high. Lets check our results to see if anything went wrong.\n\nd_train_prof %>% arrange(desc(profanity), .by_group = TRUE)\n\nOur mistake is obvious. The german word ‚Äúdie‚Äù is considered profane, since ‚Äúdie‚Äù is the verb to death. Because of that we will refrain from using the english list. Lets remove ‚Äúdie from our profanity list and try again.\n\nprofanities <- subset(profanities, V1!= \"die\") \n\nLets try again - how many words are considered as profanities?\n\nd_train_prof <- \nd_train_unnest %>% \n  select(id, token) %>% \n  mutate(profanity = token %in% profanities$V1)\n\nkable(d_train_prof %>% \n  count(profanity))\n\n\n\n\nprofanity\nn\n\n\n\n\nFALSE\n98834\n\n\nTRUE\n1383\n\n\n\n\n\nThat sounds like a reasonable amount! Now we can combine our results with our main data frame.\n\nd_train2 <-\n  d_train_senti %>% \n  full_join(d_train_prof)"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#emojis",
    "href": "posts/Hate Speech Prediction/index.html#emojis",
    "title": "Analysebericht",
    "section": "Emojis",
    "text": "Emojis\nFor emojis we source the emoji data list from the package (FitzJohn\" 2023), which includes a total of 870 emojis.\n\nemojis <- emoji(list_emoji(), pad = FALSE)\n\nSince a sole list of emojis is not really much use for predicting Hate-Speech, it would be useful to have the corresponding sentiment score of each emoji to determine their sentimental value. Luckily (Kralj Novak et al. 2015) provides the needed information on their website.\n\nemojis_sentiments <- data_read(\"data/emoji_sentiment_scores.csv\")\n\nLets see what the most negative emojis are.\n\nemojis_sentiments %>% arrange(senti_score, .by_group = TRUE)\n\nIts not suprising to see some emojis up there. Still a lot of them are also so negatively conotated because Twitter is so heavily related to politics and elections. Thus using all of the negative emojis does not seem like the best idea. Therefore we handpick a few out of our curated list:\n\nemojis_hateful <-  \n  c(\"‚ùå\",\"‚úÇÔ∏è\",\"üíâ\",\"üî™\",\"üî™\",\"üî´\",\"üí£\",\"üêç\",\"üê∑\",\"üêµ\",\"üí©\",\"üí©\",\"üí©\",\n    \"üíÄ\",\"üë∫\",\"üëπ\",\"üë¥\",\"üëµ\",\"üò∑\",\"üò°\",\"üò†\",\"üò§\",\"üòí\",\"üöë\",\"‚ò†Ô∏è\",\"üóë\",       \n    \"üëéÔ∏è\",\"ü§¢\", \"ü§Æ\",  \"üòñ\", \"üò£\", \"üò©\", \"üò®\", \"üòù\", \"üò≥\", \"üò¨\",\n    \"üòµ\",\"üñï\",\"ü§¶‚Äç‚ôÄÔ∏è\", \"ü§¶‚Äç\" )\n\nLets save our hateful_emojis_list as a dataframe in our data directory.\n\nhateful_emoji_list <-\n  tibble(emoji = emojis_hateful)\n\nsave(hateful_emoji_list, file = \"data/hateful_emoji_list.RData\")"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#word-embeddings",
    "href": "posts/Hate Speech Prediction/index.html#word-embeddings",
    "title": "Analysebericht",
    "section": "Word Embeddings",
    "text": "Word Embeddings\nFor our Word Embeddings we will be using the fastText model of pretrained german embeddings eprovided by Deepset.ai The data can be found here.\nLoading our Word embeddings model\n\nx <- \"data/model.bin\"\ndeepset_model <- load_model(x)\n\nExtracting dictionary and word vectors\n\ndeepset_dict <- get_dictionary(deepset_model)\nword_vectors <- get_word_vectors(deepset_model)\n\nCreating tibble containing the dictionary words.\n\nword_tibble <- tibble(word = deepset_dict)\n\nMerging the tibble with the the word vectors.\n\n\n\nRenaming Columns and saving the file in our data folder.\n\nnames(word_embeddings) <- c(\"word\", paste0(\"v\", sprintf(\"%03d\", 1:100)))\n#saveRDS(word_embeddings, file = \"data/word_embeddings.rds\")"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#recipe-0",
    "href": "posts/Hate Speech Prediction/index.html#recipe-0",
    "title": "Analysebericht",
    "section": "Recipe 0",
    "text": "Recipe 0\nAs a baseline recipe we use the following methods: Removal of german stop words, word stemming and normalization of all predictors and word embeddings. We also use step_mutate to use our curated profanities, sentiments, emojis and hateful emojis as predictors. To avoid running into memory issues, we apply a restriction for the amount of tokens (n = 100) using step_tokenfilter.\n\nDefining recipe 0\n\nrec0 <- recipe(c1 ~ ., data = select(d_train_id, text, c1, id)) %>%\n  update_role(id, new_role = \"id\") %>%\n  step_tokenize(text) %>%\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\n  step_stem(text) %>%\n  step_tokenfilter(text, max_tokens = 1e2) %>%\n  step_zv(all_predictors()) %>%\n  step_normalize(all_numeric_predictors(), -starts_with(\"textfeature\"), -ends_with(\"_count\")) %>%\n  step_word_embeddings(text, embeddings = word_embeddings)\n\nrec0\n\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor          1\n\nOperations:\n\nTokenization for text\nStop word removal for text\nStemming for text\nText filtering for text\nZero variance filter on all_predictors()\nCentering and scaling for all_numeric_predictors(), -starts_with(\"textfea...\nWord embeddings aggregated from text\n\n\n\n\nPreparing/Baking recipe 0\n\nrec0_prep <- prep(rec0)\n\nrec0_bake <- bake(rec0_prep, new_data = NULL)\n\nkable(head(rec0_bake))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nc1\nwordembed_text_v001\nwordembed_text_v002\nwordembed_text_v003\nwordembed_text_v004\nwordembed_text_v005\nwordembed_text_v006\nwordembed_text_v007\nwordembed_text_v008\nwordembed_text_v009\nwordembed_text_v010\nwordembed_text_v011\nwordembed_text_v012\nwordembed_text_v013\nwordembed_text_v014\nwordembed_text_v015\nwordembed_text_v016\nwordembed_text_v017\nwordembed_text_v018\nwordembed_text_v019\nwordembed_text_v020\nwordembed_text_v021\nwordembed_text_v022\nwordembed_text_v023\nwordembed_text_v024\nwordembed_text_v025\nwordembed_text_v026\nwordembed_text_v027\nwordembed_text_v028\nwordembed_text_v029\nwordembed_text_v030\nwordembed_text_v031\nwordembed_text_v032\nwordembed_text_v033\nwordembed_text_v034\nwordembed_text_v035\nwordembed_text_v036\nwordembed_text_v037\nwordembed_text_v038\nwordembed_text_v039\nwordembed_text_v040\nwordembed_text_v041\nwordembed_text_v042\nwordembed_text_v043\nwordembed_text_v044\nwordembed_text_v045\nwordembed_text_v046\nwordembed_text_v047\nwordembed_text_v048\nwordembed_text_v049\nwordembed_text_v050\nwordembed_text_v051\nwordembed_text_v052\nwordembed_text_v053\nwordembed_text_v054\nwordembed_text_v055\nwordembed_text_v056\nwordembed_text_v057\nwordembed_text_v058\nwordembed_text_v059\nwordembed_text_v060\nwordembed_text_v061\nwordembed_text_v062\nwordembed_text_v063\nwordembed_text_v064\nwordembed_text_v065\nwordembed_text_v066\nwordembed_text_v067\nwordembed_text_v068\nwordembed_text_v069\nwordembed_text_v070\nwordembed_text_v071\nwordembed_text_v072\nwordembed_text_v073\nwordembed_text_v074\nwordembed_text_v075\nwordembed_text_v076\nwordembed_text_v077\nwordembed_text_v078\nwordembed_text_v079\nwordembed_text_v080\nwordembed_text_v081\nwordembed_text_v082\nwordembed_text_v083\nwordembed_text_v084\nwordembed_text_v085\nwordembed_text_v086\nwordembed_text_v087\nwordembed_text_v088\nwordembed_text_v089\nwordembed_text_v090\nwordembed_text_v091\nwordembed_text_v092\nwordembed_text_v093\nwordembed_text_v094\nwordembed_text_v095\nwordembed_text_v096\nwordembed_text_v097\nwordembed_text_v098\nwordembed_text_v099\nwordembed_text_v100\n\n\n\n\n1\nOTHER\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n\n\n2\nOTHER\n0.1705173\n-0.6616511\n-0.2360490\n0.0683710\n1.0280830\n-0.3251859\n1.1333976\n0.8252960\n-0.5378390\n0.7560824\n1.5334624\n-0.5184664\n-0.9154094\n0.2952183\n-0.4663130\n0.1511446\n-0.5145182\n-0.1343736\n1.5142352\n0.0327072\n0.2083657\n-0.1150252\n-0.5707928\n-0.6057915\n0.2870054\n0.4496582\n0.5591611\n0.3997981\n-0.6996027\n-0.3608334\n1.1444200\n0.9068156\n1.4755962\n1.2194519\n-0.1052418\n-0.3718971\n-0.3845041\n-0.1559392\n-0.2755755\n0.6017619\n-0.2960374\n0.8520160\n0.3555014\n0.4958276\n-0.1173945\n-0.6466310\n0.3987075\n1.5161505\n0.1214860\n0.8627090\n0.4015738\n-0.3134273\n-1.1028645\n0.1975833\n-0.1803899\n-0.5832011\n0.5468701\n-0.0843101\n0.3153538\n0.3323961\n0.7965311\n-0.4495128\n-0.2556949\n-0.1417254\n-0.1077577\n0.1951436\n-0.2196960\n0.3355661\n0.0285472\n0.4606910\n-0.7571096\n-0.2227986\n-0.1647410\n0.8453106\n0.3920090\n0.6915095\n-1.1467145\n-0.0711268\n-0.2175048\n-0.2945035\n0.0655972\n-1.0872237\n-1.0964014\n-0.2006673\n-0.2568882\n-0.2473020\n0.1505071\n-0.8183470\n-0.8928060\n0.7143283\n-1.0193183\n-0.2238264\n1.2521546\n-0.7009847\n-0.1344296\n-0.3469929\n0.5592367\n0.3936044\n-0.5203777\n1.2654962\n\n\n3\nOTHER\n-0.0718034\n-0.3881005\n-0.4741701\n0.2952131\n-0.0342643\n-0.2855173\n-0.1299734\n-0.1340009\n0.0297917\n-0.4428235\n0.3643284\n-0.2519719\n-0.4176378\n0.3386248\n-0.1512924\n0.0771755\n-0.3289341\n-0.0346081\n0.4710117\n0.2872021\n-0.2911000\n-0.3147324\n-0.5099679\n0.0166199\n-0.1726374\n0.3924557\n0.0535253\n0.0159811\n-0.3629214\n-0.0169632\n0.2446892\n0.4081479\n0.5703922\n0.3306485\n0.1378234\n-0.2761500\n0.1553301\n-0.1620139\n0.0126189\n0.0084814\n-0.2287629\n0.1391533\n0.1155296\n-0.0309295\n-0.2926523\n0.2060308\n0.0352833\n0.5536110\n-0.2343113\n-0.3766860\n0.2580437\n-0.0096653\n-0.4304293\n-0.2929336\n0.2827652\n0.1292237\n-0.0471907\n-0.1353068\n-0.0343960\n-0.0300349\n0.1915074\n-0.3006558\n0.0099447\n-0.2389557\n-0.2115490\n-0.2505156\n0.6027758\n-0.2480469\n0.3295957\n0.4221208\n-0.3628489\n-0.2900164\n-0.2980791\n-0.1701689\n0.1448324\n0.0423642\n0.1992183\n0.0712101\n0.1250661\n-0.3406907\n0.5240356\n-0.1199778\n-0.0348803\n-0.1072635\n0.0460104\n0.1025959\n-0.0416946\n0.0558642\n-0.2542820\n0.2209433\n-0.8476056\n-0.2052944\n0.3307184\n-0.1258550\n0.4011300\n-0.3439502\n0.2765861\n-0.0107792\n-0.1391599\n0.1929566\n\n\n4\nOTHER\n-0.0085111\n-1.0069564\n0.1179828\n-0.0490338\n0.7585172\n0.0059626\n0.9929584\n-0.1143899\n0.1310500\n0.3445828\n1.2205725\n-0.5736997\n-1.2440808\n0.4689915\n-0.5655359\n-0.0647425\n-1.2400839\n-0.7541629\n0.3775607\n-0.0259397\n0.0323955\n-0.1318957\n-0.9763491\n-0.2599326\n0.1534037\n0.3909822\n0.3149353\n0.2164177\n-0.5465413\n0.3563783\n1.1062586\n1.3083856\n1.1106297\n1.5626093\n0.1636594\n-0.1855704\n-0.2014855\n-0.2104303\n-0.5878297\n0.9460172\n0.0000223\n0.5493760\n0.0070982\n0.0955857\n0.1869212\n-0.1218467\n-0.2646002\n0.8518468\n0.3200661\n0.8161022\n-0.4702423\n-0.4750244\n-0.8615152\n-0.3617544\n0.0367742\n0.0858123\n0.1626049\n0.0560466\n0.0924531\n0.1422715\n1.1189179\n0.2748392\n0.3107248\n0.6380534\n-0.5373157\n1.0221311\n-0.3579230\n-0.3037830\n-0.0822524\n0.3742430\n0.0347097\n-0.2821895\n-0.0191183\n0.5836134\n0.0499149\n0.8118696\n-0.8640990\n-0.4247665\n-0.2225603\n-0.8291553\n0.0581045\n-1.3873089\n-0.1723469\n-0.5633489\n0.4711508\n-0.1796506\n0.2786529\n-0.0451845\n0.0024170\n0.3011425\n-1.0393563\n-0.6167941\n0.2557316\n-0.7241205\n0.1860594\n-0.3858612\n1.0671619\n0.6950689\n-0.1327525\n0.7674235\n\n\n5\nOFFENSE\n0.1659442\n-0.1212116\n0.4297200\n0.1671278\n0.6733848\n0.3630850\n0.5895519\n-0.0315576\n-0.4714897\n0.6551241\n-0.2397894\n-0.1497419\n-0.3205699\n-0.1922833\n-0.2796791\n-0.1560503\n-0.5279630\n-0.0088302\n0.7276223\n-0.4894628\n0.0379584\n-0.2840639\n0.2365941\n0.1851194\n0.0751279\n0.6377639\n0.5987163\n-0.0640943\n0.2221429\n0.8524855\n0.5900680\n0.4170776\n0.3209653\n1.2468619\n-0.2500095\n-0.4789208\n0.8301271\n-0.2933840\n-0.4860361\n0.7855251\n-0.5412911\n0.0742704\n-0.2882261\n-0.4005688\n-0.2105889\n0.3432980\n-0.4213736\n-0.2314123\n0.3779839\n0.6083224\n-0.3759371\n-0.0844916\n-0.7473246\n-0.0249420\n-0.7806323\n0.4628508\n-0.1922061\n-0.0972560\n0.2900344\n0.1642629\n0.8632259\n0.4814199\n0.7437910\n-0.0854538\n-0.1830013\n0.4817045\n-0.2084624\n-0.2618224\n0.7382015\n1.0156894\n0.1109777\n-0.1784804\n0.0953212\n0.8036438\n0.3048914\n-0.1663137\n-0.5419402\n0.3779555\n-0.3867393\n-0.4770407\n-0.1481549\n0.2049418\n0.4554483\n-0.5357144\n0.4380139\n0.0237074\n0.3695869\n-0.1117402\n0.4347180\n-0.0466841\n-0.7723520\n0.4393246\n-0.1726162\n-0.0290350\n0.0706238\n-0.5646375\n-0.3045196\n0.2997910\n0.0993480\n0.5128943\n\n\n6\nOTHER\n0.0723996\n0.0396071\n-0.0396552\n-0.0416255\n0.5001826\n0.1102509\n0.6520016\n0.4309873\n0.0069968\n0.0520846\n0.7101114\n-0.3311372\n-0.8754475\n0.0796991\n-0.5722652\n0.6056564\n-0.2120079\n0.1687961\n1.0053588\n-0.1777948\n0.1350512\n-0.1566600\n-0.3841559\n-0.3876189\n-0.0413104\n0.3462263\n0.3196893\n0.1564686\n-0.6565381\n-0.9370736\n0.7723243\n0.7047828\n0.7672068\n0.8356602\n-0.1170150\n-0.3570145\n-0.3462146\n-0.2935857\n0.0465142\n0.2379300\n-0.8015132\n0.6603205\n0.4118967\n0.4915452\n-0.1915982\n-0.6925082\n0.2653126\n0.9218429\n0.3628542\n0.4343772\n0.4023016\n-0.3069780\n-0.7482602\n0.3383429\n-0.3373392\n-0.4506798\n-0.0573340\n-0.1377018\n0.4374293\n0.2312903\n0.4955125\n-0.4246442\n-0.2866590\n-0.2087703\n0.0167326\n-0.0989605\n0.0833743\n0.0372744\n0.5159305\n0.2718146\n-0.7249280\n-0.0545967\n-0.4269630\n0.6871249\n0.0688320\n0.3325172\n-0.3781756\n0.3928554\n0.0338916\n0.2398159\n0.4406608\n-0.5541840\n-0.8181742\n-0.7101893\n-0.2899545\n-0.0733856\n0.2115408\n-0.4931091\n-0.6207303\n0.6299949\n-0.7597253\n0.0890892\n1.0419257\n-0.2135392\n0.1020364\n-0.0196290\n0.2177937\n0.2294836\n-0.6603450\n0.4823917"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#recipe-1",
    "href": "posts/Hate Speech Prediction/index.html#recipe-1",
    "title": "Analysebericht",
    "section": "Recipe 1",
    "text": "Recipe 1\nRecipe 1 applies all steps from recipe 0 and replaces step_word_embeddings with step_tf, which converts a token variable into multiple variables containing the token counts.\n\nDefining recipe 1\n\nrec1 <- recipe(c1 ~ ., data = select(d_train_id, text, c1, id)) %>%\n  update_role(id, new_role = \"id\") %>%\n  step_tokenize(text) %>%\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\n  step_stem(text) %>%\n  step_tokenfilter(text, max_tokens = 1e2) %>%\n  step_tf(text) %>%\n  step_zv(all_predictors()) %>%\n  step_normalize(all_numeric_predictors(), -starts_with(\"textfeature\"), -ends_with(\"_count\"))\n  \n\nrec1\n\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor          1\n\nOperations:\n\nTokenization for text\nStop word removal for text\nStemming for text\nText filtering for text\nTerm frequency with text\nZero variance filter on all_predictors()\nCentering and scaling for all_numeric_predictors(), -starts_with(\"textfea...\n\n\n\n\nPreparing/Baking recipe 1\n\nrec1_prep <- prep(rec1)\n\nrec1_bake <- bake(rec1_prep, new_data = NULL)\n\nkable(head(rec1_bake))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nc1\ntf_text__macmik\ntf_text_2\ntf_text_ab\ntf_text_afd\ntf_text_amp\ntf_text_anna_iina\ntf_text_athinamala\ntf_text_beim\ntf_text_besser\ntf_text_bild\ntf_text_cdu\ntf_text_charlie_silv\ntf_text_d\ntf_text_daf√ºr\ntf_text_dank\ntf_text_dass\ntf_text_deutsch\ntf_text_deutschen\ntf_text_deutschland\ntf_text_dumm\ntf_text_eigentlich\ntf_text_einfach\ntf_text_ellibisathid\ntf_text_endlich\ntf_text_ennof_\ntf_text_erst\ntf_text_eu\ntf_text_europa\ntf_text_fdp\ntf_text_feldenfrizz\ntf_text_focusonlin\ntf_text_frage\ntf_text_frau\ntf_text_ganz\ntf_text_geht\ntf_text_gerad\ntf_text_gibt\ntf_text_gr√ºnen\ntf_text_gt\ntf_text_gut\ntf_text_h√§tte\ntf_text_heut\ntf_text_immer\ntf_text_info2099\ntf_text_islam\ntf_text_israel\ntf_text_ja\ntf_text_jahr\ntf_text_kommt\ntf_text_krippmari\ntf_text_land\ntf_text_lassen\ntf_text_lbr\ntf_text_leben\ntf_text_lifetrend\ntf_text_link\ntf_text_macht\ntf_text_machtjanix23\ntf_text_mal\ntf_text_md_franz\ntf_text_mehr\ntf_text_menschen\ntf_text_merkel\ntf_text_miriamozen\ntf_text_moslem\ntf_text_m√ºssen\ntf_text_nancypeggymandi\ntf_text_nasanas\ntf_text_nie\ntf_text_noherrman\ntf_text_norbinator2403\ntf_text_petpanther0\ntf_text_politik\ntf_text_recht\ntf_text_richtig\ntf_text_schmiddiemaik\ntf_text_schon\ntf_text_schulz\ntf_text_seit\ntf_text_sollten\ntf_text_spd\ntf_text_tagesschau\ntf_text_thomasgbau\ntf_text_troll_putin\ntf_text_trump\ntf_text_tun\ntf_text_t√ºrken\ntf_text_u\ntf_text_unser\ntf_text_viel\ntf_text_volk\ntf_text_w√§re\ntf_text_warum\ntf_text_welt\ntf_text_wer\ntf_text_willjrosenblatt\ntf_text_wissen\ntf_text_wohl\ntf_text_wurd\ntf_text_zeit\n\n\n\n\n1\nOTHER\n-0.1525923\n-0.1135821\n-0.1241518\n-0.1831511\n-0.1358281\n-0.1198975\n-0.1525923\n-0.111939\n-0.1185582\n-0.1159489\n-0.1291369\n-0.1470207\n-0.1424606\n-0.1192149\n-0.1376476\n-0.2212892\n-0.1818633\n-0.1811678\n-0.2296203\n-0.1174321\n-0.1121478\n-0.1423886\n-0.1546345\n-0.1164736\n-0.1173015\n-0.1359446\n-0.1258415\n-0.1252989\n-0.1018414\n-0.1519061\n-0.1110214\n-0.1103148\n-0.1047442\n-0.1332193\n-0.1739261\n-0.1274247\n-0.1935711\n-0.1257982\n-0.0936774\n-0.1491571\n-0.1092236\n-0.1935068\n-0.1933294\n-0.1599646\n-0.1182912\n-0.1048223\n-0.2032149\n-0.1148201\n-0.1183531\n-0.1664105\n-0.1697051\n-0.1234393\n-0.3975076\n-0.1087085\n-0.1441613\n-0.1183531\n-0.1452667\n-0.1455975\n-0.2076412\n-0.1553098\n-0.216943\n-0.1479409\n-0.2551084\n-0.1215991\n-0.1035222\n-0.1499246\n-0.1181729\n-0.1470207\n-0.1065601\n-0.1573199\n-0.1232786\n-0.1573199\n-0.1755382\n-0.143107\n-0.1190847\n-0.1427119\n-0.2375755\n-0.1157319\n-0.1491959\n-0.1137532\n-0.1576631\n-0.1110781\n-0.1519061\n-0.1232786\n-0.115067\n-0.1207959\n-0.1215991\n-0.1714487\n-0.1808551\n-0.1166118\n-0.1285038\n-0.1341874\n-0.1244491\n-0.1727265\n-0.1833771\n-0.1427119\n-0.1049151\n-0.1233318\n-0.1368046\n-0.1188249\n\n\n2\nOTHER\n-0.1525923\n-0.1135821\n-0.1241518\n-0.1831511\n-0.1358281\n-0.1198975\n-0.1525923\n-0.111939\n-0.1185582\n-0.1159489\n-0.1291369\n-0.1470207\n-0.1424606\n-0.1192149\n-0.1376476\n3.9773384\n-0.1818633\n-0.1811678\n-0.2296203\n-0.1174321\n-0.1121478\n-0.1423886\n-0.1546345\n-0.1164736\n-0.1173015\n-0.1359446\n-0.1258415\n-0.1252989\n-0.1018414\n-0.1519061\n-0.1110214\n-0.1103148\n-0.1047442\n-0.1332193\n-0.1739261\n-0.1274247\n-0.1935711\n-0.1257982\n-0.0936774\n-0.1491571\n-0.1092236\n-0.1935068\n-0.1933294\n-0.1599646\n-0.1182912\n-0.1048223\n4.4875846\n-0.1148201\n-0.1183531\n-0.1664105\n-0.1697051\n-0.1234393\n-0.3975076\n-0.1087085\n-0.1441613\n-0.1183531\n-0.1452667\n-0.1455975\n-0.2076412\n-0.1553098\n-0.216943\n-0.1479409\n-0.2551084\n-0.1215991\n-0.1035222\n-0.1499246\n-0.1181729\n-0.1470207\n-0.1065601\n-0.1573199\n-0.1232786\n-0.1573199\n-0.1755382\n6.200457\n-0.1190847\n-0.1427119\n-0.2375755\n-0.1157319\n-0.1491959\n-0.1137532\n-0.1576631\n-0.1110781\n-0.1519061\n-0.1232786\n-0.115067\n-0.1207959\n-0.1215991\n-0.1714487\n-0.1808551\n-0.1166118\n-0.1285038\n-0.1341874\n-0.1244491\n-0.1727265\n-0.1833771\n-0.1427119\n-0.1049151\n-0.1233318\n-0.1368046\n-0.1188249\n\n\n3\nOTHER\n-0.1525923\n-0.1135821\n-0.1241518\n-0.1831511\n-0.1358281\n-0.1198975\n-0.1525923\n-0.111939\n-0.1185582\n-0.1159489\n-0.1291369\n-0.1470207\n-0.1424606\n-0.1192149\n-0.1376476\n-0.2212892\n-0.1818633\n-0.1811678\n-0.2296203\n-0.1174321\n-0.1121478\n-0.1423886\n-0.1546345\n-0.1164736\n-0.1173015\n-0.1359446\n-0.1258415\n-0.1252989\n-0.1018414\n-0.1519061\n-0.1110214\n-0.1103148\n-0.1047442\n-0.1332193\n-0.1739261\n-0.1274247\n-0.1935711\n-0.1257982\n-0.0936774\n-0.1491571\n-0.1092236\n-0.1935068\n-0.1933294\n-0.1599646\n-0.1182912\n-0.1048223\n-0.2032149\n-0.1148201\n-0.1183531\n-0.1664105\n-0.1697051\n-0.1234393\n-0.3975076\n-0.1087085\n-0.1441613\n-0.1183531\n-0.1452667\n-0.1455975\n-0.2076412\n-0.1553098\n-0.216943\n-0.1479409\n-0.2551084\n-0.1215991\n-0.1035222\n-0.1499246\n-0.1181729\n-0.1470207\n-0.1065601\n-0.1573199\n-0.1232786\n-0.1573199\n-0.1755382\n-0.143107\n-0.1190847\n-0.1427119\n-0.2375755\n-0.1157319\n-0.1491959\n-0.1137532\n-0.1576631\n-0.1110781\n-0.1519061\n-0.1232786\n-0.115067\n-0.1207959\n-0.1215991\n-0.1714487\n-0.1808551\n-0.1166118\n-0.1285038\n-0.1341874\n-0.1244491\n5.3031406\n-0.1833771\n-0.1427119\n-0.1049151\n-0.1233318\n-0.1368046\n-0.1188249\n\n\n4\nOTHER\n-0.1525923\n-0.1135821\n-0.1241518\n-0.1831511\n-0.1358281\n-0.1198975\n-0.1525923\n-0.111939\n-0.1185582\n-0.1159489\n-0.1291369\n-0.1470207\n-0.1424606\n-0.1192149\n-0.1376476\n-0.2212892\n-0.1818633\n-0.1811678\n-0.2296203\n-0.1174321\n-0.1121478\n-0.1423886\n-0.1546345\n-0.1164736\n-0.1173015\n6.6735214\n-0.1258415\n-0.1252989\n-0.1018414\n-0.1519061\n-0.1110214\n-0.1103148\n-0.1047442\n-0.1332193\n-0.1739261\n-0.1274247\n-0.1935711\n-0.1257982\n-0.0936774\n-0.1491571\n-0.1092236\n-0.1935068\n-0.1933294\n-0.1599646\n-0.1182912\n-0.1048223\n-0.2032149\n-0.1148201\n-0.1183531\n-0.1664105\n-0.1697051\n-0.1234393\n-0.3975076\n-0.1087085\n-0.1441613\n-0.1183531\n-0.1452667\n-0.1455975\n-0.2076412\n-0.1553098\n-0.216943\n-0.1479409\n-0.2551084\n-0.1215991\n-0.1035222\n-0.1499246\n-0.1181729\n-0.1470207\n-0.1065601\n-0.1573199\n-0.1232786\n-0.1573199\n5.1212746\n6.200457\n-0.1190847\n-0.1427119\n-0.2375755\n-0.1157319\n-0.1491959\n-0.1137532\n-0.1576631\n-0.1110781\n-0.1519061\n-0.1232786\n-0.115067\n-0.1207959\n-0.1215991\n-0.1714487\n-0.1808551\n-0.1166118\n-0.1285038\n-0.1341874\n-0.1244491\n-0.1727265\n-0.1833771\n-0.1427119\n-0.1049151\n-0.1233318\n-0.1368046\n-0.1188249\n\n\n5\nOFFENSE\n-0.1525923\n-0.1135821\n-0.1241518\n-0.1831511\n-0.1358281\n-0.1198975\n-0.1525923\n-0.111939\n-0.1185582\n-0.1159489\n-0.1291369\n-0.1470207\n-0.1424606\n-0.1192149\n-0.1376476\n-0.2212892\n-0.1818633\n-0.1811678\n-0.2296203\n-0.1174321\n-0.1121478\n-0.1423886\n-0.1546345\n-0.1164736\n-0.1173015\n-0.1359446\n-0.1258415\n-0.1252989\n-0.1018414\n-0.1519061\n-0.1110214\n-0.1103148\n-0.1047442\n-0.1332193\n-0.1739261\n-0.1274247\n-0.1935711\n-0.1257982\n-0.0936774\n-0.1491571\n-0.1092236\n-0.1935068\n-0.1933294\n-0.1599646\n-0.1182912\n-0.1048223\n-0.2032149\n-0.1148201\n-0.1183531\n-0.1664105\n-0.1697051\n-0.1234393\n-0.3975076\n-0.1087085\n-0.1441613\n-0.1183531\n-0.1452667\n-0.1455975\n-0.2076412\n-0.1553098\n-0.216943\n-0.1479409\n-0.2551084\n-0.1215991\n-0.1035222\n-0.1499246\n-0.1181729\n-0.1470207\n-0.1065601\n-0.1573199\n-0.1232786\n-0.1573199\n-0.1755382\n-0.143107\n-0.1190847\n-0.1427119\n-0.2375755\n-0.1157319\n-0.1491959\n-0.1137532\n5.5238815\n-0.1110781\n-0.1519061\n-0.1232786\n-0.115067\n-0.1207959\n-0.1215991\n-0.1714487\n-0.1808551\n-0.1166118\n-0.1285038\n-0.1341874\n-0.1244491\n-0.1727265\n-0.1833771\n-0.1427119\n-0.1049151\n-0.1233318\n-0.1368046\n-0.1188249\n\n\n6\nOTHER\n-0.1525923\n-0.1135821\n-0.1241518\n-0.1831511\n-0.1358281\n-0.1198975\n-0.1525923\n-0.111939\n-0.1185582\n-0.1159489\n-0.1291369\n-0.1470207\n-0.1424606\n-0.1192149\n-0.1376476\n-0.2212892\n-0.1818633\n-0.1811678\n-0.2296203\n-0.1174321\n-0.1121478\n-0.1423886\n-0.1546345\n-0.1164736\n-0.1173015\n-0.1359446\n-0.1258415\n-0.1252989\n-0.1018414\n-0.1519061\n-0.1110214\n-0.1103148\n-0.1047442\n-0.1332193\n5.5955842\n-0.1274247\n-0.1935711\n-0.1257982\n-0.0936774\n-0.1491571\n-0.1092236\n-0.1935068\n-0.1933294\n-0.1599646\n-0.1182912\n-0.1048223\n4.4875846\n-0.1148201\n-0.1183531\n-0.1664105\n-0.1697051\n-0.1234393\n-0.3975076\n-0.1087085\n-0.1441613\n-0.1183531\n-0.1452667\n-0.1455975\n-0.2076412\n-0.1553098\n-0.216943\n-0.1479409\n-0.2551084\n-0.1215991\n-0.1035222\n-0.1499246\n-0.1181729\n-0.1470207\n-0.1065601\n-0.1573199\n-0.1232786\n-0.1573199\n-0.1755382\n-0.143107\n-0.1190847\n-0.1427119\n-0.2375755\n-0.1157319\n-0.1491959\n-0.1137532\n-0.1576631\n-0.1110781\n-0.1519061\n-0.1232786\n-0.115067\n-0.1207959\n-0.1215991\n-0.1714487\n-0.1808551\n-0.1166118\n-0.1285038\n-0.1341874\n-0.1244491\n-0.1727265\n-0.1833771\n-0.1427119\n-0.1049151\n-0.1233318\n-0.1368046\n-0.1188249"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#recipe-2",
    "href": "posts/Hate Speech Prediction/index.html#recipe-2",
    "title": "Analysebericht",
    "section": "Recipe 2",
    "text": "Recipe 2\nIn this recipe we change step_tf to step_tfidf, which results in an inverse Document Frequency of our tokens.\n\nDefining recipe 2\n\nrec2 <- recipe(c1 ~ ., data = select(d_train_id, text, c1, id)) %>%\n  update_role(id, new_role = \"id\") %>%\n  step_tokenize(text) %>%\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>%\n  step_stem(text) %>%\n  step_tokenfilter(text, max_tokens = 1e2) %>%\n  step_tfidf(text) %>%\n  step_zv(all_predictors()) %>%\n  step_normalize(all_numeric_predictors(), -starts_with(\"textfeature\"), -ends_with(\"_count\"))\n  \n\nrec2\n\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor          1\n\nOperations:\n\nTokenization for text\nStop word removal for text\nStemming for text\nText filtering for text\nTerm frequency-inverse document frequency with text\nZero variance filter on all_predictors()\nCentering and scaling for all_numeric_predictors(), -starts_with(\"textfea...\n\n\n\n\nPreparing/Baking recipe 2\n\nrec2_prep <- prep(rec2)\n\nrec2_bake <- bake(rec2_prep, new_data = NULL)\n\nkable(head(rec2_bake))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nc1\ntfidf_text__macmik\ntfidf_text_2\ntfidf_text_ab\ntfidf_text_afd\ntfidf_text_amp\ntfidf_text_anna_iina\ntfidf_text_athinamala\ntfidf_text_beim\ntfidf_text_besser\ntfidf_text_bild\ntfidf_text_cdu\ntfidf_text_charlie_silv\ntfidf_text_d\ntfidf_text_daf√ºr\ntfidf_text_dank\ntfidf_text_dass\ntfidf_text_deutsch\ntfidf_text_deutschen\ntfidf_text_deutschland\ntfidf_text_dumm\ntfidf_text_eigentlich\ntfidf_text_einfach\ntfidf_text_ellibisathid\ntfidf_text_endlich\ntfidf_text_ennof_\ntfidf_text_erst\ntfidf_text_eu\ntfidf_text_europa\ntfidf_text_fdp\ntfidf_text_feldenfrizz\ntfidf_text_focusonlin\ntfidf_text_frage\ntfidf_text_frau\ntfidf_text_ganz\ntfidf_text_geht\ntfidf_text_gerad\ntfidf_text_gibt\ntfidf_text_gr√ºnen\ntfidf_text_gt\ntfidf_text_gut\ntfidf_text_h√§tte\ntfidf_text_heut\ntfidf_text_immer\ntfidf_text_info2099\ntfidf_text_islam\ntfidf_text_israel\ntfidf_text_ja\ntfidf_text_jahr\ntfidf_text_kommt\ntfidf_text_krippmari\ntfidf_text_land\ntfidf_text_lassen\ntfidf_text_lbr\ntfidf_text_leben\ntfidf_text_lifetrend\ntfidf_text_link\ntfidf_text_macht\ntfidf_text_machtjanix23\ntfidf_text_mal\ntfidf_text_md_franz\ntfidf_text_mehr\ntfidf_text_menschen\ntfidf_text_merkel\ntfidf_text_miriamozen\ntfidf_text_moslem\ntfidf_text_m√ºssen\ntfidf_text_nancypeggymandi\ntfidf_text_nasanas\ntfidf_text_nie\ntfidf_text_noherrman\ntfidf_text_norbinator2403\ntfidf_text_petpanther0\ntfidf_text_politik\ntfidf_text_recht\ntfidf_text_richtig\ntfidf_text_schmiddiemaik\ntfidf_text_schon\ntfidf_text_schulz\ntfidf_text_seit\ntfidf_text_sollten\ntfidf_text_spd\ntfidf_text_tagesschau\ntfidf_text_thomasgbau\ntfidf_text_troll_putin\ntfidf_text_trump\ntfidf_text_tun\ntfidf_text_t√ºrken\ntfidf_text_u\ntfidf_text_unser\ntfidf_text_viel\ntfidf_text_volk\ntfidf_text_w√§re\ntfidf_text_warum\ntfidf_text_welt\ntfidf_text_wer\ntfidf_text_willjrosenblatt\ntfidf_text_wissen\ntfidf_text_wohl\ntfidf_text_wurd\ntfidf_text_zeit\n\n\n\n\n1\nOTHER\n-0.1360347\n-0.0996499\n-0.1032711\n-0.1592451\n-0.1213167\n-0.102885\n-0.1360347\n-0.0906374\n-0.0998114\n-0.1001756\n-0.1057297\n-0.1436627\n-0.1343985\n-0.0965294\n-0.1194715\n-0.1919072\n-0.156776\n-0.1510832\n-0.2000219\n-0.1041115\n-0.0933891\n-0.1219992\n-0.111245\n-0.1005732\n-0.1170189\n-0.1139481\n-0.1151372\n-0.1073693\n-0.0916503\n-0.1460452\n-0.0971611\n-0.0941145\n-0.0912738\n-0.114278\n-0.1489552\n-0.1094171\n-0.1653518\n-0.107322\n-0.090492\n-0.1221851\n-0.0958297\n-0.1672072\n-0.166724\n-0.0785723\n-0.1057581\n-0.0888228\n-0.1730153\n-0.0993418\n-0.0993865\n-0.142428\n-0.1462041\n-0.1071178\n-0.4070735\n-0.0884154\n-0.1428669\n-0.1018528\n-0.1229545\n-0.1102224\n-0.1740563\n-0.1115021\n-0.1842209\n-0.1233943\n-0.2234377\n-0.1036738\n-0.0924792\n-0.1307096\n-0.1150833\n-0.1103349\n-0.0892396\n-0.0944897\n-0.0641121\n-0.0841552\n-0.1518153\n-0.1190563\n-0.0997825\n-0.141485\n-0.1996958\n-0.1007793\n-0.1239379\n-0.0978532\n-0.1317353\n-0.0990086\n-0.1409355\n-0.1188606\n-0.1016846\n-0.1045154\n-0.1048411\n-0.1538774\n-0.1553256\n-0.0982374\n-0.1096479\n-0.1128127\n-0.1046822\n-0.1496353\n-0.1584449\n-0.141485\n-0.091336\n-0.1052044\n-0.1138908\n-0.1013744\n\n\n2\nOTHER\n-0.1360347\n-0.0996499\n-0.1032711\n-0.1592451\n-0.1213167\n-0.102885\n-0.1360347\n-0.0906374\n-0.0998114\n-0.1001756\n-0.1057297\n-0.1436627\n-0.1343985\n-0.0965294\n-0.1194715\n3.4468883\n-0.156776\n-0.1510832\n-0.2000219\n-0.1041115\n-0.0933891\n-0.1219992\n-0.111245\n-0.1005732\n-0.1170189\n-0.1139481\n-0.1151372\n-0.1073693\n-0.0916503\n-0.1460452\n-0.0971611\n-0.0941145\n-0.0912738\n-0.114278\n-0.1489552\n-0.1094171\n-0.1653518\n-0.107322\n-0.090492\n-0.1221851\n-0.0958297\n-0.1672072\n-0.166724\n-0.0785723\n-0.1057581\n-0.0888228\n3.4000247\n-0.0993418\n-0.0993865\n-0.142428\n-0.1462041\n-0.1071178\n-0.4070735\n-0.0884154\n-0.1428669\n-0.1018528\n-0.1229545\n-0.1102224\n-0.1740563\n-0.1115021\n-0.1842209\n-0.1233943\n-0.2234377\n-0.1036738\n-0.0924792\n-0.1307096\n-0.1150833\n-0.1103349\n-0.0892396\n-0.0944897\n-0.0641121\n-0.0841552\n-0.1518153\n4.7112064\n-0.0997825\n-0.141485\n-0.1996958\n-0.1007793\n-0.1239379\n-0.0978532\n-0.1317353\n-0.0990086\n-0.1409355\n-0.1188606\n-0.1016846\n-0.1045154\n-0.1048411\n-0.1538774\n-0.1553256\n-0.0982374\n-0.1096479\n-0.1128127\n-0.1046822\n-0.1496353\n-0.1584449\n-0.141485\n-0.091336\n-0.1052044\n-0.1138908\n-0.1013744\n\n\n3\nOTHER\n-0.1360347\n-0.0996499\n-0.1032711\n-0.1592451\n-0.1213167\n-0.102885\n-0.1360347\n-0.0906374\n-0.0998114\n-0.1001756\n-0.1057297\n-0.1436627\n-0.1343985\n-0.0965294\n-0.1194715\n-0.1919072\n-0.156776\n-0.1510832\n-0.2000219\n-0.1041115\n-0.0933891\n-0.1219992\n-0.111245\n-0.1005732\n-0.1170189\n-0.1139481\n-0.1151372\n-0.1073693\n-0.0916503\n-0.1460452\n-0.0971611\n-0.0941145\n-0.0912738\n-0.114278\n-0.1489552\n-0.1094171\n-0.1653518\n-0.107322\n-0.090492\n-0.1221851\n-0.0958297\n-0.1672072\n-0.166724\n-0.0785723\n-0.1057581\n-0.0888228\n-0.1730153\n-0.0993418\n-0.0993865\n-0.142428\n-0.1462041\n-0.1071178\n-0.4070735\n-0.0884154\n-0.1428669\n-0.1018528\n-0.1229545\n-0.1102224\n-0.1740563\n-0.1115021\n-0.1842209\n-0.1233943\n-0.2234377\n-0.1036738\n-0.0924792\n-0.1307096\n-0.1150833\n-0.1103349\n-0.0892396\n-0.0944897\n-0.0641121\n-0.0841552\n-0.1518153\n-0.1190563\n-0.0997825\n-0.141485\n-0.1996958\n-0.1007793\n-0.1239379\n-0.0978532\n-0.1317353\n-0.0990086\n-0.1409355\n-0.1188606\n-0.1016846\n-0.1045154\n-0.1048411\n-0.1538774\n-0.1553256\n-0.0982374\n-0.1096479\n-0.1128127\n-0.1046822\n10.9991033\n-0.1584449\n-0.141485\n-0.091336\n-0.1052044\n-0.1138908\n-0.1013744\n\n\n4\nOTHER\n-0.1360347\n-0.0996499\n-0.1032711\n-0.1592451\n-0.1213167\n-0.102885\n-0.1360347\n-0.0906374\n-0.0998114\n-0.1001756\n-0.1057297\n-0.1436627\n-0.1343985\n-0.0965294\n-0.1194715\n-0.1919072\n-0.156776\n-0.1510832\n-0.2000219\n-0.1041115\n-0.0933891\n-0.1219992\n-0.111245\n-0.1005732\n-0.1170189\n5.7532137\n-0.1151372\n-0.1073693\n-0.0916503\n-0.1460452\n-0.0971611\n-0.0941145\n-0.0912738\n-0.114278\n-0.1489552\n-0.1094171\n-0.1653518\n-0.107322\n-0.090492\n-0.1221851\n-0.0958297\n-0.1672072\n-0.166724\n-0.0785723\n-0.1057581\n-0.0888228\n-0.1730153\n-0.0993418\n-0.0993865\n-0.142428\n-0.1462041\n-0.1071178\n-0.4070735\n-0.0884154\n-0.1428669\n-0.1018528\n-0.1229545\n-0.1102224\n-0.1740563\n-0.1115021\n-0.1842209\n-0.1233943\n-0.2234377\n-0.1036738\n-0.0924792\n-0.1307096\n-0.1150833\n-0.1103349\n-0.0892396\n-0.0944897\n-0.0641121\n-0.0841552\n4.3093516\n4.7112064\n-0.0997825\n-0.141485\n-0.1996958\n-0.1007793\n-0.1239379\n-0.0978532\n-0.1317353\n-0.0990086\n-0.1409355\n-0.1188606\n-0.1016846\n-0.1045154\n-0.1048411\n-0.1538774\n-0.1553256\n-0.0982374\n-0.1096479\n-0.1128127\n-0.1046822\n-0.1496353\n-0.1584449\n-0.141485\n-0.091336\n-0.1052044\n-0.1138908\n-0.1013744\n\n\n5\nOFFENSE\n-0.1360347\n-0.0996499\n-0.1032711\n-0.1592451\n-0.1213167\n-0.102885\n-0.1360347\n-0.0906374\n-0.0998114\n-0.1001756\n-0.1057297\n-0.1436627\n-0.1343985\n-0.0965294\n-0.1194715\n-0.1919072\n-0.156776\n-0.1510832\n-0.2000219\n-0.1041115\n-0.0933891\n-0.1219992\n-0.111245\n-0.1005732\n-0.1170189\n-0.1139481\n-0.1151372\n-0.1073693\n-0.0916503\n-0.1460452\n-0.0971611\n-0.0941145\n-0.0912738\n-0.114278\n-0.1489552\n-0.1094171\n-0.1653518\n-0.107322\n-0.090492\n-0.1221851\n-0.0958297\n-0.1672072\n-0.166724\n-0.0785723\n-0.1057581\n-0.0888228\n-0.1730153\n-0.0993418\n-0.0993865\n-0.142428\n-0.1462041\n-0.1071178\n-0.4070735\n-0.0884154\n-0.1428669\n-0.1018528\n-0.1229545\n-0.1102224\n-0.1740563\n-0.1115021\n-0.1842209\n-0.1233943\n-0.2234377\n-0.1036738\n-0.0924792\n-0.1307096\n-0.1150833\n-0.1103349\n-0.0892396\n-0.0944897\n-0.0641121\n-0.0841552\n-0.1518153\n-0.1190563\n-0.0997825\n-0.141485\n-0.1996958\n-0.1007793\n-0.1239379\n-0.0978532\n13.9000535\n-0.0990086\n-0.1409355\n-0.1188606\n-0.1016846\n-0.1045154\n-0.1048411\n-0.1538774\n-0.1553256\n-0.0982374\n-0.1096479\n-0.1128127\n-0.1046822\n-0.1496353\n-0.1584449\n-0.141485\n-0.091336\n-0.1052044\n-0.1138908\n-0.1013744\n\n\n6\nOTHER\n-0.1360347\n-0.0996499\n-0.1032711\n-0.1592451\n-0.1213167\n-0.102885\n-0.1360347\n-0.0906374\n-0.0998114\n-0.1001756\n-0.1057297\n-0.1436627\n-0.1343985\n-0.0965294\n-0.1194715\n-0.1919072\n-0.156776\n-0.1510832\n-0.2000219\n-0.1041115\n-0.0933891\n-0.1219992\n-0.111245\n-0.1005732\n-0.1170189\n-0.1139481\n-0.1151372\n-0.1073693\n-0.0916503\n-0.1460452\n-0.0971611\n-0.0941145\n-0.0912738\n-0.114278\n6.1420345\n-0.1094171\n-0.1653518\n-0.107322\n-0.090492\n-0.1221851\n-0.0958297\n-0.1672072\n-0.166724\n-0.0785723\n-0.1057581\n-0.0888228\n5.1865448\n-0.0993418\n-0.0993865\n-0.142428\n-0.1462041\n-0.1071178\n-0.4070735\n-0.0884154\n-0.1428669\n-0.1018528\n-0.1229545\n-0.1102224\n-0.1740563\n-0.1115021\n-0.1842209\n-0.1233943\n-0.2234377\n-0.1036738\n-0.0924792\n-0.1307096\n-0.1150833\n-0.1103349\n-0.0892396\n-0.0944897\n-0.0641121\n-0.0841552\n-0.1518153\n-0.1190563\n-0.0997825\n-0.141485\n-0.1996958\n-0.1007793\n-0.1239379\n-0.0978532\n-0.1317353\n-0.0990086\n-0.1409355\n-0.1188606\n-0.1016846\n-0.1045154\n-0.1048411\n-0.1538774\n-0.1553256\n-0.0982374\n-0.1096479\n-0.1128127\n-0.1046822\n-0.1496353\n-0.1584449\n-0.141485\n-0.091336\n-0.1052044\n-0.1138908\n-0.1013744"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#naive-bayes",
    "href": "posts/Hate Speech Prediction/index.html#naive-bayes",
    "title": "Analysebericht",
    "section": "Naive Bayes",
    "text": "Naive Bayes\n\nm_nb <- naive_Bayes() %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"naivebayes\")\n\nm_nb\n\nNaive Bayes Model Specification (classification)\n\nComputational engine: naivebayes"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#boost-trees---xgboost",
    "href": "posts/Hate Speech Prediction/index.html#boost-trees---xgboost",
    "title": "Analysebericht",
    "section": "Boost Trees - XGBoost",
    "text": "Boost Trees - XGBoost\n\ndoParallel::registerDoParallel()\n  \nm_xgb <- boost_tree(trees = tune()) %>% \nset_engine(\"xgboost\", nthreads = 12) %>% \nset_mode(\"classification\")"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#lasso-model",
    "href": "posts/Hate Speech Prediction/index.html#lasso-model",
    "title": "Analysebericht",
    "section": "Lasso Model",
    "text": "Lasso Model\n-> Regression model, penalized with the L1-norm (sum of the absolute coefficients).\n\ndoParallel::registerDoParallel()\ncores <- parallel::detectCores(logical = TRUE)\n\nm_l <- logistic_reg(penalty = tune(), mixture = 1) %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"glmnet\", num.threads = cores)\n\nm_l\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nEngine-Specific Arguments:\n  num.threads = cores\n\nComputational engine: glmnet"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#ridge-regression",
    "href": "posts/Hate Speech Prediction/index.html#ridge-regression",
    "title": "Analysebericht",
    "section": "Ridge Regression",
    "text": "Ridge Regression\n-> Creates a model that is penalized with the L2-norm. With that we can shrink the coefficient values.\n\ndoParallel::registerDoParallel()\ncores <- parallel::detectCores(logical = TRUE)\n\nm_rr <- logistic_reg(penalty = tune(), mixture = 0) %>%\n    set_mode(\"classification\") %>%\n    set_engine(\"glmnet\")\n\nm_rr\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0\n\nComputational engine: glmnet"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#elastic-net-model",
    "href": "posts/Hate Speech Prediction/index.html#elastic-net-model",
    "title": "Analysebericht",
    "section": "Elastic Net Model",
    "text": "Elastic Net Model\n-> Creates a regression model that is penalized with both the L1-norm and L2-norm. More or less a combination of Lasso and Ridge.\n\nm_en <- logistic_reg(penalty = tune(), mixture = 0.5) %>%\n    set_mode(\"classification\") %>%\n    set_engine(\"glmnet\")\n\nm_en\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 0.5\n\nComputational engine: glmnet"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#cross-validation",
    "href": "posts/Hate Speech Prediction/index.html#cross-validation",
    "title": "Analysebericht",
    "section": "Cross Validation",
    "text": "Cross Validation\nWe will be using the regular 10x cross validation.\n\nset.seed(13)\ncv_folds <- vfold_cv(d_train_id, v = 10)"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#lambda-grid",
    "href": "posts/Hate Speech Prediction/index.html#lambda-grid",
    "title": "Analysebericht",
    "section": "Lambda Grid",
    "text": "Lambda Grid\nWe will be using a lambda grid with a total 30 levels.\n\nlambda_grid <- grid_regular(penalty(), levels = 30)"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec0---naive-bayes",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec0---naive-bayes",
    "title": "Analysebericht",
    "section": "Workflow Rec0 - Naive Bayes",
    "text": "Workflow Rec0 - Naive Bayes\n\nwf_r0_nb <- workflow() %>%\n  add_recipe(rec0) %>%\n  add_model(m_nb)\n\n\nFit\n\nfit_r0_nb <- fit_resamples(wf_r0_nb, cv_folds)\n\n\n\nPerformance\n\nwf_r0_nb_performance <- collect_metrics(fit_r0_nb)\n\nwf_r0_nb_performance\n\n# A tibble: 2 √ó 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.552    10 0.00525 Preprocessor1_Model1\n2 roc_auc  binary     0.605    10 0.00608 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec1---naive-bayes",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec1---naive-bayes",
    "title": "Analysebericht",
    "section": "Workflow Rec1 - Naive Bayes",
    "text": "Workflow Rec1 - Naive Bayes\n\nwf_r1_nb <- workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(m_nb)\n\n\nFit\n\nfit_r1_nb <- fit_resamples(wf_r1_nb, cv_folds)\n\n\n\nPerformance\n\nwf_r1_nb_performance <- collect_metrics(fit_r1_nb)\n\nwf_r1_nb_performance\n\n# A tibble: 2 √ó 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.663    10 0.00515 Preprocessor1_Model1\n2 roc_auc  binary     0.655    10 0.00539 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec2---naive-bayes",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec2---naive-bayes",
    "title": "Analysebericht",
    "section": "Workflow Rec2 - Naive Bayes",
    "text": "Workflow Rec2 - Naive Bayes\n\nwf_r2_nb <- workflow() %>%\n  add_recipe(rec2) %>%\n  add_model(m_nb)\n\n\nFit\n\nfit_r2_nb <- fit_resamples(wf_r2_nb, cv_folds)\n\n\n\nPerformance\n\nwf_r2_nb_performance <- collect_metrics(fit_r2_nb)\n\nwf_r2_nb_performance\n\n# A tibble: 2 √ó 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.664    10 0.00446 Preprocessor1_Model1\n2 roc_auc  binary     0.613    10 0.00276 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec0---xgboost",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec0---xgboost",
    "title": "Analysebericht",
    "section": "Workflow Rec0 - XGBoost",
    "text": "Workflow Rec0 - XGBoost\n\nwf_r0_xgb <- workflow() %>%\n  add_recipe(rec0) %>%\n  add_model(m_xgb)\n\n\nFit\n\nset.seed(2246)\n\nfit_r0_xgb <- tune_grid(wf_r0_xgb, cv_folds, grid = 10, \n                        control = control_resamples(save_pred = TRUE))\n\n\n\nPerformance\n\nwf_r0_xgb_performance <- collect_metrics(fit_r0_xgb)\n\nwf_r0_xgb_performance\n\n# A tibble: 20 √ó 7\n   trees .metric  .estimator  mean     n std_err .config              \n   <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1    23 accuracy binary     0.667    10 0.00596 Preprocessor1_Model01\n 2    23 roc_auc  binary     0.629    10 0.00704 Preprocessor1_Model01\n 3   223 accuracy binary     0.675    10 0.00627 Preprocessor1_Model02\n 4   223 roc_auc  binary     0.620    10 0.00635 Preprocessor1_Model02\n 5   459 accuracy binary     0.677    10 0.00547 Preprocessor1_Model03\n 6   459 roc_auc  binary     0.617    10 0.00704 Preprocessor1_Model03\n 7   795 accuracy binary     0.677    10 0.00582 Preprocessor1_Model04\n 8   795 roc_auc  binary     0.617    10 0.00715 Preprocessor1_Model04\n 9   838 accuracy binary     0.675    10 0.00572 Preprocessor1_Model05\n10   838 roc_auc  binary     0.616    10 0.00715 Preprocessor1_Model05\n11  1150 accuracy binary     0.677    10 0.00564 Preprocessor1_Model06\n12  1150 roc_auc  binary     0.615    10 0.00714 Preprocessor1_Model06\n13  1239 accuracy binary     0.679    10 0.00557 Preprocessor1_Model07\n14  1239 roc_auc  binary     0.615    10 0.00719 Preprocessor1_Model07\n15  1464 accuracy binary     0.678    10 0.00532 Preprocessor1_Model08\n16  1464 roc_auc  binary     0.616    10 0.00705 Preprocessor1_Model08\n17  1620 accuracy binary     0.677    10 0.00573 Preprocessor1_Model09\n18  1620 roc_auc  binary     0.615    10 0.00711 Preprocessor1_Model09\n19  1930 accuracy binary     0.677    10 0.00559 Preprocessor1_Model10\n20  1930 roc_auc  binary     0.615    10 0.00689 Preprocessor1_Model10"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec1---xgboost",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec1---xgboost",
    "title": "Analysebericht",
    "section": "Workflow Rec1 - XGBoost",
    "text": "Workflow Rec1 - XGBoost\n\nwf_r1_xgb <- workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(m_xgb)\n\n\nFit\n\nset.seed(2246)\n\nfit_r1_xgb <- tune_grid(wf_r1_xgb, cv_folds, grid = 10, \n                        control = control_resamples(save_pred = TRUE))\n\n\n\nPerformance\n\nwf_r1_xgb_performance <- collect_metrics(fit_r1_xgb)\n\nwf_r1_xgb_performance\n\n# A tibble: 20 √ó 7\n   trees .metric  .estimator  mean     n std_err .config              \n   <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1    23 accuracy binary     0.693    10 0.00332 Preprocessor1_Model01\n 2    23 roc_auc  binary     0.661    10 0.00646 Preprocessor1_Model01\n 3   223 accuracy binary     0.687    10 0.00573 Preprocessor1_Model02\n 4   223 roc_auc  binary     0.648    10 0.00851 Preprocessor1_Model02\n 5   459 accuracy binary     0.683    10 0.00669 Preprocessor1_Model03\n 6   459 roc_auc  binary     0.643    10 0.00931 Preprocessor1_Model03\n 7   795 accuracy binary     0.681    10 0.00707 Preprocessor1_Model04\n 8   795 roc_auc  binary     0.639    10 0.00963 Preprocessor1_Model04\n 9   838 accuracy binary     0.681    10 0.00681 Preprocessor1_Model05\n10   838 roc_auc  binary     0.639    10 0.00973 Preprocessor1_Model05\n11  1150 accuracy binary     0.679    10 0.00646 Preprocessor1_Model06\n12  1150 roc_auc  binary     0.638    10 0.00942 Preprocessor1_Model06\n13  1239 accuracy binary     0.678    10 0.00656 Preprocessor1_Model07\n14  1239 roc_auc  binary     0.638    10 0.00981 Preprocessor1_Model07\n15  1464 accuracy binary     0.677    10 0.00719 Preprocessor1_Model08\n16  1464 roc_auc  binary     0.637    10 0.00950 Preprocessor1_Model08\n17  1620 accuracy binary     0.675    10 0.00634 Preprocessor1_Model09\n18  1620 roc_auc  binary     0.637    10 0.00954 Preprocessor1_Model09\n19  1930 accuracy binary     0.675    10 0.00594 Preprocessor1_Model10\n20  1930 roc_auc  binary     0.635    10 0.00884 Preprocessor1_Model10"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec2---xgboost",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec2---xgboost",
    "title": "Analysebericht",
    "section": "Workflow Rec2 - XGBoost",
    "text": "Workflow Rec2 - XGBoost\n\nwf_r2_xgb <- workflow() %>%\n  add_recipe(rec2) %>%\n  add_model(m_xgb)\n\n\nFit\n\nset.seed(2246)\n\nfit_r2_xgb <- tune_grid(wf_r2_xgb, cv_folds, grid = 10, \n                        control = control_resamples(save_pred = TRUE))\n\n\n\nPerformance\n\nwf_r2_xgb_performance <- collect_metrics(fit_r2_xgb)\n\nwf_r2_xgb_performance\n\n# A tibble: 20 √ó 7\n   trees .metric  .estimator  mean     n std_err .config              \n   <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1    23 accuracy binary     0.695    10 0.00383 Preprocessor1_Model01\n 2    23 roc_auc  binary     0.655    10 0.00585 Preprocessor1_Model01\n 3   223 accuracy binary     0.680    10 0.00391 Preprocessor1_Model02\n 4   223 roc_auc  binary     0.644    10 0.00679 Preprocessor1_Model02\n 5   459 accuracy binary     0.672    10 0.00308 Preprocessor1_Model03\n 6   459 roc_auc  binary     0.631    10 0.00849 Preprocessor1_Model03\n 7   795 accuracy binary     0.669    10 0.00435 Preprocessor1_Model04\n 8   795 roc_auc  binary     0.628    10 0.00914 Preprocessor1_Model04\n 9   838 accuracy binary     0.668    10 0.00481 Preprocessor1_Model05\n10   838 roc_auc  binary     0.628    10 0.00916 Preprocessor1_Model05\n11  1150 accuracy binary     0.669    10 0.00505 Preprocessor1_Model06\n12  1150 roc_auc  binary     0.624    10 0.00914 Preprocessor1_Model06\n13  1239 accuracy binary     0.667    10 0.00530 Preprocessor1_Model07\n14  1239 roc_auc  binary     0.623    10 0.00901 Preprocessor1_Model07\n15  1464 accuracy binary     0.670    10 0.00449 Preprocessor1_Model08\n16  1464 roc_auc  binary     0.622    10 0.00882 Preprocessor1_Model08\n17  1620 accuracy binary     0.666    10 0.00423 Preprocessor1_Model09\n18  1620 roc_auc  binary     0.622    10 0.00904 Preprocessor1_Model09\n19  1930 accuracy binary     0.667    10 0.00420 Preprocessor1_Model10\n20  1930 roc_auc  binary     0.621    10 0.00873 Preprocessor1_Model10"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec0---lasso",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec0---lasso",
    "title": "Analysebericht",
    "section": "Workflow Rec0 - Lasso",
    "text": "Workflow Rec0 - Lasso\n\nwf_r0_l <- workflow() %>%\n  add_recipe(rec0) %>%\n  add_model(m_l)\n\n\nFit\n\nset.seed(2246)\n\nfit_r0_l <- tune_grid(wf_r0_l, cv_folds, grid = lambda_grid, control = control_resamples(save_pred = TRUE))\n\n\n\nPerformance\n\nwf_r0_l_performance <- collect_metrics(fit_r0_l)\n\nwf_r0_l_performance\n\n# A tibble: 60 √ó 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.691    10 0.00813 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.644    10 0.00954 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.691    10 0.00813 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.644    10 0.00954 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.691    10 0.00813 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.644    10 0.00954 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.691    10 0.00813 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.644    10 0.00954 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.691    10 0.00813 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.644    10 0.00954 Preprocessor1_Model05\n# ‚Ä¶ with 50 more rows"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec1---lasso",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec1---lasso",
    "title": "Analysebericht",
    "section": "Workflow Rec1 - Lasso",
    "text": "Workflow Rec1 - Lasso\n\nwf_r1_l <- workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(m_l)\n\n\nFit\n\nset.seed(2246)\n\nfit_r1_l <- tune_grid(wf_r1_l, cv_folds, grid = lambda_grid, control = control_resamples(save_pred = TRUE))\n\n\n\nPerformance\n\nwf_r1_l_performance <- collect_metrics(fit_r1_l)\n\nwf_r1_l_performance\n\n# A tibble: 60 √ó 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.684    10 0.00793 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.644    10 0.00748 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.684    10 0.00793 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.644    10 0.00748 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.684    10 0.00793 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.644    10 0.00748 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.684    10 0.00793 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.644    10 0.00748 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.684    10 0.00793 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.644    10 0.00748 Preprocessor1_Model05\n# ‚Ä¶ with 50 more rows"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec2---lasso",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec2---lasso",
    "title": "Analysebericht",
    "section": "Workflow Rec2 - Lasso",
    "text": "Workflow Rec2 - Lasso\n\nwf_r2_l <- workflow() %>%\n  add_recipe(rec2) %>%\n  add_model(m_l)\n\n\nFit\n\nset.seed(2246)\n\nfit_r2_l <- tune_grid(wf_r2_l, cv_folds, grid = lambda_grid, control = control_resamples(save_pred = TRUE))\n\n\n\nPerformance\n\nwf_r2_l_performance <- collect_metrics(fit_r2_l)\n\nwf_r2_l_performance\n\n# A tibble: 60 √ó 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.683    10 0.00614 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.647    10 0.00728 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.683    10 0.00614 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.647    10 0.00728 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.683    10 0.00614 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.647    10 0.00728 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.683    10 0.00614 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.647    10 0.00728 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.683    10 0.00614 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.647    10 0.00728 Preprocessor1_Model05\n# ‚Ä¶ with 50 more rows"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec0---ridge-regression",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec0---ridge-regression",
    "title": "Analysebericht",
    "section": "Workflow Rec0 - Ridge Regression",
    "text": "Workflow Rec0 - Ridge Regression\n\nwf_r0_rr <- workflow() %>%\n  add_recipe(rec0) %>%\n  add_model(m_rr)\n\n\nFit\n\nset.seed(2246)\n\nfit_r0_rr <- tune_grid(wf_r0_rr, cv_folds, grid = lambda_grid, control = control_resamples(save_pred = TRUE))\n\n\n\nPerformance\n\nwf_r0_rr_performance <- collect_metrics(fit_r0_rr)\n\nwf_r0_rr_performance\n\n# A tibble: 60 √ó 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.687    10 0.00693 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.644    10 0.00949 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.687    10 0.00693 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.644    10 0.00949 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.687    10 0.00693 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.644    10 0.00949 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.687    10 0.00693 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.644    10 0.00949 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.687    10 0.00693 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.644    10 0.00949 Preprocessor1_Model05\n# ‚Ä¶ with 50 more rows"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec1---ridge-regression",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec1---ridge-regression",
    "title": "Analysebericht",
    "section": "Workflow Rec1 - Ridge Regression",
    "text": "Workflow Rec1 - Ridge Regression\n\nwf_r1_rr <- workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(m_rr)\n\n\nFit\n\nset.seed(2246)\n\nfit_r1_rr <- tune_grid(wf_r1_rr, cv_folds, grid = lambda_grid, control = control_resamples(save_pred = TRUE))\n\n\n\nPerformance\n\nwf_r1_rr_performance <- collect_metrics(fit_r1_rr)\n\nwf_r1_rr_performance\n\n# A tibble: 60 √ó 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.685    10 0.00772 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.645    10 0.00752 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.685    10 0.00772 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.645    10 0.00752 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.685    10 0.00772 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.645    10 0.00752 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.685    10 0.00772 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.645    10 0.00752 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.685    10 0.00772 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.645    10 0.00752 Preprocessor1_Model05\n# ‚Ä¶ with 50 more rows"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#workflow-rec2---ridge-regression",
    "href": "posts/Hate Speech Prediction/index.html#workflow-rec2---ridge-regression",
    "title": "Analysebericht",
    "section": "Workflow Rec2 - Ridge Regression",
    "text": "Workflow Rec2 - Ridge Regression\n\nwf_r2_rr <- workflow() %>%\n  add_recipe(rec2) %>%\n  add_model(m_rr)\n\n\nFit\n\nset.seed(2246)\n\nfit_r2_rr <- tune_grid(wf_r2_rr, cv_folds, grid = lambda_grid, control = control_resamples(save_pred = TRUE))\n\n\n\nPerformance\n\nwf_r2_rr_performance <- collect_metrics(fit_r2_rr)\n\nwf_r2_rr_performance\n\n# A tibble: 60 √ó 7\n    penalty .metric  .estimator  mean     n std_err .config              \n      <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1 1   e-10 accuracy binary     0.684    10 0.00581 Preprocessor1_Model01\n 2 1   e-10 roc_auc  binary     0.647    10 0.00733 Preprocessor1_Model01\n 3 2.21e-10 accuracy binary     0.684    10 0.00581 Preprocessor1_Model02\n 4 2.21e-10 roc_auc  binary     0.647    10 0.00733 Preprocessor1_Model02\n 5 4.89e-10 accuracy binary     0.684    10 0.00581 Preprocessor1_Model03\n 6 4.89e-10 roc_auc  binary     0.647    10 0.00733 Preprocessor1_Model03\n 7 1.08e- 9 accuracy binary     0.684    10 0.00581 Preprocessor1_Model04\n 8 1.08e- 9 roc_auc  binary     0.647    10 0.00733 Preprocessor1_Model04\n 9 2.40e- 9 accuracy binary     0.684    10 0.00581 Preprocessor1_Model05\n10 2.40e- 9 roc_auc  binary     0.647    10 0.00733 Preprocessor1_Model05\n# ‚Ä¶ with 50 more rows"
  },
  {
    "objectID": "posts/Hate Speech Prediction/index.html#prediction",
    "href": "posts/Hate Speech Prediction/index.html#prediction",
    "title": "Analysebericht",
    "section": "Prediction",
    "text": "Prediction\nLets predict using the test data.\n\nfit_final_test <- fit_final_train %>% \n  predict(d_test_id)\n\nMerge predictions with test data.\n\nfit_final_test_id <- fit_final_test %>% \n  mutate(id = row_number())\n\npredictions <- fit_final_test_id %>% full_join(d_test_id, by = \"id\")\n\nAnd finally lets see the metrics of our prediction, after factorizing the c1 column.\n\npredictions$c1 <- as.factor(predictions$c1)\n\ntest_metrics <- predictions %>% metrics(c1, .pred_class)\n\nkable(test_metrics)\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\n\n\naccuracy\nbinary\n0.6653454\n\n\nkap\nbinary\n0.0648416"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  }
]